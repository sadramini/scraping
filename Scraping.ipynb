{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6485d4eb-a633-45c1-804d-54a782f44228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Please log in manually.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Press Enter when logged in...  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logged in successfully.\n",
      "ğŸ“… Navigated to Calendar page.\n",
      "ğŸ”„ Scanning for all row indices...\n",
      "âœ… Found 12 unique rows.\n",
      "\n",
      "ğŸ” Processing row 0...\n",
      "\n",
      "ğŸ” Processing row 1...\n",
      "\n",
      "ğŸ” Processing row 2...\n",
      "\n",
      "ğŸ” Processing row 3...\n",
      "\n",
      "ğŸ” Processing row 4...\n",
      "\n",
      "ğŸ” Processing row 5...\n",
      "\n",
      "ğŸ” Processing row 6...\n",
      "\n",
      "ğŸ” Processing row 7...\n",
      "\n",
      "ğŸ” Processing row 8...\n",
      "\n",
      "ğŸ” Processing row 9...\n",
      "\n",
      "ğŸ” Processing row 10...\n",
      "\n",
      "ğŸ” Processing row 11...\n",
      "\n",
      "âŒ No transcripts captured.\n",
      "ğŸ Done.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import pyperclip\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CHROMEDRIVER_PATH = \"./chromedriver\"\n",
    "CSV_FILE = \"quartr_transcripts.csv\"\n",
    "SCROLL_STEP = 400\n",
    "PAUSE = 0.5\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def scroll_to_index(driver, container, index, wait, max_attempts=20):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            driver.execute_script(\"\"\"\n",
    "                const container = arguments[0];\n",
    "                container.scrollTop = arguments[1] * 100;\n",
    "            \"\"\", container, int(index))\n",
    "            time.sleep(PAUSE)\n",
    "            row = driver.find_element(By.CSS_SELECTOR, f\"div[data-index='{index}']\")\n",
    "            return row\n",
    "        except:\n",
    "            time.sleep(0.3)\n",
    "    return None\n",
    "\n",
    "def extract_transcript(driver, wait):\n",
    "    transcript_text = \"\"\n",
    "    try:\n",
    "        main_xpath = \"//div[contains(@class,'document-content')]\"\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, main_xpath)))\n",
    "        sections = driver.find_elements(By.XPATH, f\"{main_xpath}//div[contains(@class, 'group') and contains(@class, 'relative')]\")\n",
    "\n",
    "        for section in sections:\n",
    "            speaker_info = \"\"\n",
    "            try:\n",
    "                name = section.find_element(By.XPATH, \".//div[contains(@class, 'font-semibold')]\").text.strip()\n",
    "                position = section.find_element(By.XPATH, \".//div[contains(@class, 'font-medium')]//span\").text.strip()\n",
    "                speaker_info = f\"[{name} ({position})]: \"\n",
    "            except:\n",
    "                try:\n",
    "                    name = section.find_element(By.XPATH, \".//div[contains(@class, 'font-semibold')]\").text.strip()\n",
    "                    speaker_info = f\"[{name}]: \"\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            body = \" \".join([\n",
    "                s.text.strip()\n",
    "                for s in section.find_elements(By.XPATH, \".//span[contains(@class, 'select-text')]\")\n",
    "                if s.text.strip()\n",
    "            ])\n",
    "            if body:\n",
    "                transcript_text += f\"{speaker_info}{body}\\n\\n\"\n",
    "\n",
    "        if transcript_text.strip():\n",
    "            return transcript_text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try copy button\n",
    "    try:\n",
    "        copy_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@data-sentry-component='TranscriptCopyAction']\")))\n",
    "        copy_button.click()\n",
    "        time.sleep(0.7)\n",
    "        return pyperclip.paste().strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Raw fallback\n",
    "    try:\n",
    "        main_container = driver.find_element(By.XPATH, \"//div[contains(@class,'document-content')]\")\n",
    "        return main_container.text.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    scraped_data = []\n",
    "\n",
    "    # â”€â”€ LOGIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    driver.get(\n",
    "        \"https://auth.quartr.com/realms/prod/protocol/openid-connect/auth\"\n",
    "        \"?response_type=code&client_id=web&redirect_uri=https%3A%2F%2Fweb.quartr.com\"\n",
    "        \"%2Fapi%2Fauth%2Fcallback%2Fkeycloak&code_challenge=iQ7FuQ_Xo7pFKL2wwzpLRRTbVqGLTpG-NmyU0oG7iKQ\"\n",
    "        \"&code_challenge_method=S256&scope=openid+profile+email\"\n",
    "    )\n",
    "    print(\"ğŸ”‘ Please log in manually.\")\n",
    "    input(\"    Press Enter when logged in... \")\n",
    "    wait.until(EC.url_contains(\"web.quartr.com\"))\n",
    "    print(\"âœ… Logged in successfully.\")\n",
    "\n",
    "    # â”€â”€ NAVIGATE TO CALENDAR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        calendar_button = wait.until(EC.element_to_be_clickable((\n",
    "            By.XPATH, \"//a[@href='/calendar' and @data-menu-list-item='true']\"\n",
    "        )))\n",
    "        calendar_button.click()\n",
    "        print(\"ğŸ“… Navigated to Calendar page.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to click the Calendar button: {e}\")\n",
    "        driver.quit()\n",
    "        return\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-index]\")))\n",
    "\n",
    "    # â”€â”€ FIND SCROLLABLE CONTAINER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    row_sample = driver.find_element(By.CSS_SELECTOR, \"div[data-index]\")\n",
    "    scrollable_container = driver.execute_script(\"\"\"\n",
    "        let el = arguments[0];\n",
    "        while (el.parentNode) {\n",
    "            el = el.parentNode;\n",
    "            if (el.scrollHeight > el.clientHeight + 10) return el;\n",
    "        }\n",
    "        return null;\n",
    "    \"\"\", row_sample)\n",
    "    if not scrollable_container:\n",
    "        print(\"âŒ Could not find scrollable container.\")\n",
    "        driver.quit()\n",
    "        return\n",
    "\n",
    "    # â”€â”€ COLLECT UNIQUE data-index ROWS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"ğŸ”„ Scanning for all row indices...\")\n",
    "    unique_indexes = set()\n",
    "    last_count = 0\n",
    "    no_new_scrolls = 0\n",
    "    max_no_new = 7\n",
    "\n",
    "    while no_new_scrolls < max_no_new:\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"div[data-index]\")\n",
    "        for r in rows:\n",
    "            idx = r.get_attribute(\"data-index\")\n",
    "            if idx:\n",
    "                unique_indexes.add(idx)\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTop += arguments[1];\", scrollable_container, SCROLL_STEP)\n",
    "        time.sleep(PAUSE)\n",
    "\n",
    "        if len(unique_indexes) == last_count:\n",
    "            no_new_scrolls += 1\n",
    "        else:\n",
    "            no_new_scrolls = 0\n",
    "            last_count = len(unique_indexes)\n",
    "\n",
    "    print(f\"âœ… Found {len(unique_indexes)} unique rows.\")\n",
    "\n",
    "    # â”€â”€ PROCESS EACH ROW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for idx in sorted(unique_indexes, key=lambda x: int(x)):\n",
    "        try:\n",
    "            print(f\"\\nğŸ” Processing row {idx}...\")\n",
    "            row = scroll_to_index(driver, scrollable_container, idx, wait)\n",
    "            if not row:\n",
    "                print(f\"âš ï¸ Row {idx} not found after scrolling.\")\n",
    "                continue\n",
    "\n",
    "            boxes = row.find_elements(By.CSS_SELECTOR, \"div.px-3\")\n",
    "            for box_idx, box in enumerate(boxes):\n",
    "                try:\n",
    "                    button = box.find_element(By.CSS_SELECTOR, 'span[data-sentry-component=\"ShowTranscriptButton\"]')\n",
    "\n",
    "                    # Extract company and title\n",
    "                    company = \"\"\n",
    "                    title = \"\"\n",
    "                    try:\n",
    "                        company = box.find_element(By.CSS_SELECTOR, 'span.text-clip').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        title = box.find_element(By.CSS_SELECTOR, 'span.text-ellipsis').text.strip()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    print(f\"â–¶ï¸ Row {idx}, Box {box_idx} â†’ {company} â€“ {title}\")\n",
    "\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", button)\n",
    "                    time.sleep(0.5)\n",
    "                    button.click()\n",
    "                    time.sleep(1.5)\n",
    "\n",
    "                    transcript = extract_transcript(driver, wait)\n",
    "\n",
    "                    if transcript:\n",
    "                        scraped_data.append({\n",
    "                            \"Row\": idx,\n",
    "                            \"Box\": box_idx,\n",
    "                            \"Company\": company,\n",
    "                            \"Title\": title,\n",
    "                            \"Transcript\": transcript\n",
    "                        })\n",
    "                        print(f\"âœ… Transcript extracted ({len(transcript)} characters)\")\n",
    "                    else:\n",
    "                        print(\"âš ï¸ Empty transcript.\")\n",
    "\n",
    "                    driver.back()\n",
    "                    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-index]\")))\n",
    "                    time.sleep(PAUSE)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except WebDriverException as wde:\n",
    "            print(f\"âŒ WebDriver error on row {idx}: {wde}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error on row {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # â”€â”€ SAVE TO CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if scraped_data:\n",
    "        with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"Row\", \"Box\", \"Company\", \"Title\", \"Transcript\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(scraped_data)\n",
    "        print(f\"\\nğŸ’¾ Saved {len(scraped_data)} transcripts to {CSV_FILE}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ No transcripts captured.\")\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"ğŸ Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
